{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55917294",
   "metadata": {},
   "source": [
    "# Optimization Techniques\n",
    "\n",
    "Optimizing your cloud-native remote sensing workflows can significantly reduce computation time, memory usage, and cloud costs.\n",
    "\n",
    "## 1. Spatial and Temporal Filtering\n",
    "\n",
    "The first rule of optimization is: **Load only what you need.**\n",
    "\n",
    "- **Spatial**: Use the tightest possible `bbox` or `geometry`. If you're analyzing a city, don't load the whole province.\n",
    "- **Temporal**: Filter date ranges strictly. If you only need summer months, don't load the full year and then filter in XArray; filter at the STAC/GEE API level.\n",
    "- **Bands**: Only load the bands required for your index (e.g., Red and NIR for NDVI).\n",
    "\n",
    "## 2. Chunking Optimization\n",
    "\n",
    "As discussed in the Dask section, chunking is crucial.\n",
    "\n",
    "- **Align chunks with data**: Zarr and COG files have internal tiling. Try to make your Dask chunks a multiple of the file's internal tiles.\n",
    "- **Minimize shuffling**: Avoid operations that require data to move between workers (like global sorting or complex re-gridding) if possible.\n",
    "\n",
    "## 3. Projection and Alignment\n",
    "\n",
    "Re-projecting large datasets is computationally expensive.\n",
    "\n",
    "- **Common CRS**: Try to work in the native CRS of the data. If you must re-project, do it *after* spatial/temporal subsetting.\n",
    "- **Lazy Reprojection**: Use `odc-stac` or `stackstac` which can handle re-projection lazily during data loading.\n",
    "\n",
    "## 4. Lazy Operations and Persistence\n",
    "\n",
    "- **Don't `.compute()` early**: String multiple operations together (Indices → Resampling → Statistics) and run a single `.compute()` at the end.\n",
    "- **Use `.persist()`**: If you're going to use a filtered dataset multiple times in the same session, use `ds = ds.persist()`. This keeps the data in the memory of the Dask workers, preventing it from being re-loaded or re-calculated from the source.\n",
    "\n",
    "## 5. Optimized Storage (Zarr)\n",
    "\n",
    "Zarr is significantly faster than COG for time series analysis because it is optimized for \"slicing\" along the time dimension.\n",
    "\n",
    "- **Consolidated Metadata**: Always use `consolidated=True` when writing or reading Zarr. This allows Dask to find all chunks with a single HTTP request rather than hundreds.\n",
    "- **Compression**: Use Blosc or Zstd compression to reduce data transfer size.\n",
    "\n",
    "## 6. EECU Optimization (Earth Engine)\n",
    "\n",
    "When using XEE/Earth Engine:\n",
    "\n",
    "- **Simplify Geometries**: Complex polygons with thousands of vertices can slow down filtering. Use `geometry.simplify()`.\n",
    "- **Reduce resolution**: Use a larger `scale` (e.g., 30m instead of 10m) for large area overviews.\n",
    "\n",
    "## Checklist for High-Performance Code\n",
    "\n",
    "- [ ] Filtered by BBOX and Date at the API level?\n",
    "- [ ] Only required bands selected?\n",
    "- [ ] Dask Dashboard shows workers are busy (not idling)?\n",
    "- [ ] Memory usage per worker is stable?\n",
    "- [ ] No small, fragmented chunks?\n",
    "- [ ] Using Zarr for time-series and COG for spatial composites?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
