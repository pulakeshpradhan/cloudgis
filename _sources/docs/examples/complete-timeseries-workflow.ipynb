{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "043c3ec2",
   "metadata": {},
   "source": [
    "# Complete Time Series Workflow\n",
    "\n",
    "## Overview\n",
    "\n",
    "This practical example demonstrates a complete end-to-end workflow for time series analysis using cloud-native tools. We'll cover three approaches:\n",
    "\n",
    "1. **Geemap Tiled Download** \u2192 Read with XArray\n",
    "2. **Direct XEE Approach** \u2192 Stream from Earth Engine\n",
    "3. **Dask + Zarr** \u2192 Scalable time series processing\n",
    "\n",
    "## Scenario\n",
    "\n",
    "**Objective**: Analyze NDVI time series for a region to detect vegetation changes over 2023.\n",
    "\n",
    "**Area**: Agricultural region in Uttar Pradesh, India  \n",
    "**Data**: Sentinel-2 monthly composites  \n",
    "**Output**: Time series analysis with trend detection\n",
    "\n",
    "## Approach 1: Geemap Tiled Download + XArray\n",
    "\n",
    "### Step 1: Download Monthly Composites with Geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f42d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import os\n",
    "import calendar\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='spatialgeography')\n",
    "\n",
    "# Create output directory\n",
    "output_folder = 'timeseries_data'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Define region of interest\n",
    "roi = ee.Geometry.Rectangle([82.0, 26.5, 82.5, 27.0])\n",
    "\n",
    "# Download monthly NDVI composites for 2023\n",
    "print(\"Downloading monthly NDVI composites...\")\n",
    "\n",
    "monthly_files = []\n",
    "\n",
    "for month in range(1, 13):\n",
    "    # Define date range\n",
    "    start_date = f'2023-{month:02d}-01'\n",
    "    if month == 12:\n",
    "        end_date = '2024-01-01'\n",
    "    else:\n",
    "        end_date = f'2023-{month+1:02d}-01'\n",
    "    \n",
    "    # Get Sentinel-2 data\n",
    "    s2 = ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
    "        .filterBounds(roi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n",
    "    \n",
    "    # Cloud masking function\n",
    "    def mask_clouds(image):\n",
    "        qa = image.select('QA60')\n",
    "        cloud_mask = qa.bitwiseAnd(1 << 10).eq(0).And(\n",
    "                     qa.bitwiseAnd(1 << 11).eq(0))\n",
    "        return image.updateMask(cloud_mask)\n",
    "    \n",
    "    # Apply cloud mask and create median composite\n",
    "    s2_masked = s2.map(mask_clouds)\n",
    "    median = s2_masked.median()\n",
    "    \n",
    "    # Calculate NDVI (processing done server-side in Earth Engine)\n",
    "    ndvi = median.normalizedDifference(['B8', 'B4']).clip(roi)\n",
    "    \n",
    "    # Download using geemap (automatic tiling, no EECU usage)\n",
    "    month_name = calendar.month_name[month]\n",
    "    output_file = os.path.join(output_folder, f'ndvi_2023_{month:02d}.tif')\n",
    "    \n",
    "    try:\n",
    "        geemap.download_ee_image(\n",
    "            ndvi,\n",
    "            filename=output_file,\n",
    "            region=roi,\n",
    "            scale=20,  # 20m resolution\n",
    "            crs='EPSG:4326',\n",
    "            num_threads=4  # Parallel download\n",
    "        )\n",
    "        monthly_files.append(output_file)\n",
    "        print(f\"\u2713 Downloaded: {month_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u2717 Failed {month_name}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nTotal files downloaded: {len(monthly_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1abe71",
   "metadata": {},
   "source": [
    "### Step 2: Read Downloaded Files with XArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all monthly files into XArray Dataset\n",
    "print(\"\\nReading files with XArray...\")\n",
    "\n",
    "# Read first file to get metadata\n",
    "first_raster = rxr.open_rasterio(monthly_files[0], masked=True)\n",
    "\n",
    "# Create list to store all monthly data\n",
    "monthly_data = []\n",
    "time_coords = []\n",
    "\n",
    "for i, file in enumerate(monthly_files):\n",
    "    # Read raster\n",
    "    raster = rxr.open_rasterio(file, masked=True)\n",
    "    \n",
    "    # Extract data (remove band dimension as we only have NDVI)\n",
    "    data = raster.squeeze('band', drop=True)\n",
    "    \n",
    "    # Add to list\n",
    "    monthly_data.append(data)\n",
    "    \n",
    "    # Create time coordinate (middle of month)\n",
    "    month = i + 1\n",
    "    time_coords.append(datetime(2023, month, 15))\n",
    "\n",
    "# Stack along time dimension\n",
    "ndvi_ts = xr.concat(monthly_data, dim='time')\n",
    "ndvi_ts = ndvi_ts.assign_coords(time=time_coords)\n",
    "ndvi_ts.name = 'NDVI'\n",
    "\n",
    "print(ndvi_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd1319",
   "metadata": {},
   "source": [
    "### Step 3: Analyze Time Series with XArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcfdf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "print(\"\\nCalculating statistics...\")\n",
    "\n",
    "# Temporal statistics\n",
    "ndvi_mean = ndvi_ts.mean(dim='time')\n",
    "ndvi_std = ndvi_ts.std(dim='time')\n",
    "ndvi_max = ndvi_ts.max(dim='time')\n",
    "ndvi_min = ndvi_ts.min(dim='time')\n",
    "\n",
    "# Spatial mean time series\n",
    "ndvi_spatial_mean = ndvi_ts.mean(dim=['x', 'y'])\n",
    "\n",
    "# Calculate trend using linear regression\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_trend(data):\n",
    "    \"\"\"Calculate linear trend.\"\"\"\n",
    "    x = np.arange(len(data))\n",
    "    mask = ~np.isnan(data)\n",
    "    if mask.sum() < 3:  # Need at least 3 points\n",
    "        return np.nan\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x[mask], data[mask])\n",
    "    return slope\n",
    "\n",
    "# Apply trend calculation\n",
    "trend = xr.apply_ufunc(\n",
    "    calculate_trend,\n",
    "    ndvi_ts,\n",
    "    input_core_dims=[['time']],\n",
    "    vectorize=True\n",
    ")\n",
    "\n",
    "print(f\"Mean NDVI: {ndvi_mean.mean().values:.3f}\")\n",
    "print(f\"NDVI Std Dev: {ndvi_std.mean().values:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85232556",
   "metadata": {},
   "source": [
    "### Step 4: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Mean NDVI\n",
    "ndvi_mean.plot(ax=axes[0, 0], cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "axes[0, 0].set_title('Mean NDVI (2023)')\n",
    "axes[0, 0].set_axis_off()\n",
    "\n",
    "# 2. Standard Deviation\n",
    "ndvi_std.plot(ax=axes[0, 1], cmap='YlOrRd')\n",
    "axes[0, 1].set_title('NDVI Standard Deviation')\n",
    "axes[0, 1].set_axis_off()\n",
    "\n",
    "# 3. Trend\n",
    "trend.plot(ax=axes[0, 2], cmap='RdBu_r', center=0)\n",
    "axes[0, 2].set_title('NDVI Trend (slope)')\n",
    "axes[0, 2].set_axis_off()\n",
    "\n",
    "# 4. Time series plot\n",
    "ndvi_spatial_mean.plot(ax=axes[1, 0], marker='o')\n",
    "axes[1, 0].set_title('Spatial Mean NDVI Time Series')\n",
    "axes[1, 0].set_ylabel('NDVI')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Seasonal comparison (Jan vs Jul)\n",
    "ndvi_ts.isel(time=0).plot(ax=axes[1, 1], cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "axes[1, 1].set_title('January NDVI')\n",
    "axes[1, 1].set_axis_off()\n",
    "\n",
    "ndvi_ts.isel(time=6).plot(ax=axes[1, 2], cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "axes[1, 2].set_title('July NDVI')\n",
    "axes[1, 2].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, 'ndvi_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAnalysis complete! Results saved to {output_folder}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1afd0d",
   "metadata": {},
   "source": [
    "## Approach 2: Direct XEE Approach (Streaming)\n",
    "\n",
    "### Stream Time Series Directly from Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a01a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import xee\n",
    "import ee\n",
    "\n",
    "# Initialize Earth Engine\n",
    "ee.Initialize(project='spatialgeography')\n",
    "\n",
    "# Define region and time range\n",
    "roi = ee.Geometry.Rectangle([82.0, 26.5, 82.5, 27.0])\n",
    "\n",
    "# Get Sentinel-2 ImageCollection\n",
    "s2_collection = ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
    "    .filterBounds(roi) \\\n",
    "    .filterDate('2023-01-01', '2023-12-31') \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n",
    "\n",
    "# Cloud masking\n",
    "def mask_s2_clouds(image):\n",
    "    qa = image.select('QA60')\n",
    "    cloud_mask = qa.bitwiseAnd(1 << 10).eq(0).And(\n",
    "                 qa.bitwiseAnd(1 << 11).eq(0))\n",
    "    return image.updateMask(cloud_mask)\n",
    "\n",
    "# Apply cloud mask\n",
    "s2_masked = s2_collection.map(mask_s2_clouds)\n",
    "\n",
    "# Open as XArray Dataset using XEE (streaming, no download!)\n",
    "print(\"Opening Earth Engine data with XEE...\")\n",
    "\n",
    "ds_xee = xr.open_dataset(\n",
    "    s2_masked,\n",
    "    engine='ee',\n",
    "    geometry=roi,\n",
    "    scale=20,\n",
    "    crs='EPSG:4326',\n",
    "    ee_mask_value=-9999\n",
    ")\n",
    "\n",
    "# IMPORTANT: Sort by time immediately for resampling to work\n",
    "ds_xee = ds_xee.sortby('time')\n",
    "print(ds_xee)\n",
    "\n",
    "# Calculate NDVI directly on the streamed data\n",
    "print(\"\\nCalculating NDVI...\")\n",
    "ndvi_xee = (ds_xee.B8 - ds_xee.B4) / (ds_xee.B8 + ds_xee.B4)\n",
    "\n",
    "# Resample to monthly\n",
    "print(\"Resampling to monthly...\")\n",
    "ndvi_monthly_xee = ndvi_xee.resample(time='1M').median()\n",
    "\n",
    "# Calculate spatial mean\n",
    "# XEE dimensions are usually lon/lat or X/Y depending on CRS\n",
    "spatial_dims = [d for d in list(ds_xee.dims) if d not in ['time', 'band']]\n",
    "ndvi_ts_xee = ndvi_monthly_xee.mean(dim=spatial_dims)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# XEE approach\n",
    "ndvi_ts_xee.plot(ax=axes[0], marker='o', label='XEE (Streaming)')\n",
    "axes[0].set_title('NDVI Time Series - XEE Approach')\n",
    "axes[0].set_ylabel('NDVI')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Downloaded approach (from previous)\n",
    "ndvi_spatial_mean.plot(ax=axes[1], marker='s', label='Geemap (Downloaded)')\n",
    "axes[1].set_title('NDVI Time Series - Geemap Approach')\n",
    "axes[1].set_ylabel('NDVI')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2713 XEE streaming approach complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b026c538",
   "metadata": {},
   "source": [
    "## Approach 3: Dask + Zarr for Scalable Processing\n",
    "\n",
    "### Step 1: Load Data with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c96ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.array as da\n",
    "\n",
    "# Start Dask cluster\n",
    "print(\"Starting Dask cluster...\")\n",
    "cluster = LocalCluster(n_workers=4, threads_per_worker=2, memory_limit='2GB')\n",
    "client = Client(cluster)\n",
    "print(client)\n",
    "\n",
    "# Load downloaded files with Dask chunking\n",
    "print(\"\\nLoading data with Dask...\")\n",
    "\n",
    "# Read files with chunking\n",
    "monthly_data_dask = []\n",
    "time_coords = []\n",
    "\n",
    "for i, file in enumerate(monthly_files):\n",
    "    # Read with rioxarray and chunk\n",
    "    raster = rxr.open_rasterio(file, masked=True, chunks={'x': 256, 'y': 256})\n",
    "    data = raster.squeeze('band', drop=True)\n",
    "    monthly_data_dask.append(data)\n",
    "    \n",
    "    month = i + 1\n",
    "    time_coords.append(datetime(2023, month, 15))\n",
    "\n",
    "# Stack with Dask\n",
    "ndvi_dask = xr.concat(monthly_data_dask, dim='time')\n",
    "ndvi_dask = ndvi_dask.assign_coords(time=time_coords)\n",
    "ndvi_dask = ndvi_dask.chunk({'time': 3, 'x': 256, 'y': 256})\n",
    "ndvi_dask.name = 'NDVI'\n",
    "\n",
    "print(ndvi_dask)\n",
    "print(f\"\\nDask chunks: {ndvi_dask.chunks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85525267",
   "metadata": {},
   "source": [
    "### Step 2: Save to Zarr (Cloud-Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2281aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "from numcodecs import Blosc\n",
    "\n",
    "# Configure compression\n",
    "compressor = Blosc(cname='zstd', clevel=3, shuffle=Blosc.SHUFFLE)\n",
    "\n",
    "# Save to Zarr\n",
    "zarr_path = os.path.join(output_folder, 'ndvi_timeseries.zarr')\n",
    "\n",
    "print(f\"\\nSaving to Zarr: {zarr_path}\")\n",
    "\n",
    "# Convert to dataset and save\n",
    "ndvi_dataset = ndvi_dask.to_dataset()\n",
    "\n",
    "# Add metadata\n",
    "ndvi_dataset.attrs['title'] = 'NDVI Time Series 2023'\n",
    "ndvi_dataset.attrs['source'] = 'Sentinel-2 SR'\n",
    "ndvi_dataset.attrs['region'] = 'Uttar Pradesh, India'\n",
    "ndvi_dataset.attrs['resolution'] = '20m'\n",
    "\n",
    "# Save with compression\n",
    "encoding = {\n",
    "    'NDVI': {\n",
    "        'compressor': compressor,\n",
    "        'chunks': (3, 256, 256)\n",
    "    }\n",
    "}\n",
    "\n",
    "ndvi_dataset.to_zarr(\n",
    "    zarr_path,\n",
    "    mode='w',\n",
    "    encoding=encoding,\n",
    "    consolidated=True\n",
    ")\n",
    "\n",
    "print(\"\u2713 Saved to Zarr!\")\n",
    "\n",
    "# Check file size\n",
    "import shutil\n",
    "zarr_size = sum(f.stat().st_size for f in Path(zarr_path).rglob('*') if f.is_file())\n",
    "print(f\"Zarr archive size: {zarr_size / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c29080",
   "metadata": {},
   "source": [
    "### Step 3: Load from Zarr and Process with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from Zarr (instant, lazy loading)\n",
    "print(\"\\nLoading from Zarr...\")\n",
    "ndvi_from_zarr = xr.open_zarr(zarr_path, consolidated=True)\n",
    "\n",
    "print(ndvi_from_zarr)\n",
    "\n",
    "# Perform computations with Dask\n",
    "print(\"\\nPerforming Dask computations...\")\n",
    "\n",
    "# 1. Calculate anomalies\n",
    "climatology = ndvi_from_zarr.NDVI.mean(dim='time')\n",
    "anomalies = ndvi_from_zarr.NDVI - climatology\n",
    "\n",
    "# 2. Calculate rolling mean (smoothing)\n",
    "rolling_mean = ndvi_from_zarr.NDVI.rolling(time=3, center=True).mean()\n",
    "\n",
    "# 3. Calculate percentiles\n",
    "percentile_10 = ndvi_from_zarr.NDVI.quantile(0.1, dim='time')\n",
    "percentile_90 = ndvi_from_zarr.NDVI.quantile(0.9, dim='time')\n",
    "\n",
    "# Compute all at once (parallel with Dask)\n",
    "print(\"Computing results...\")\n",
    "results = xr.Dataset({\n",
    "    'anomalies': anomalies,\n",
    "    'rolling_mean': rolling_mean,\n",
    "    'p10': percentile_10,\n",
    "    'p90': percentile_90\n",
    "})\n",
    "\n",
    "# Trigger computation\n",
    "results_computed = results.compute()\n",
    "\n",
    "print(\"\u2713 Computations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c911008",
   "metadata": {},
   "source": [
    "### Step 4: Advanced Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal decomposition\n",
    "print(\"\\nPerforming seasonal analysis...\")\n",
    "\n",
    "# Group by season\n",
    "seasonal_mean = ndvi_from_zarr.NDVI.groupby('time.season').mean()\n",
    "\n",
    "# Monthly statistics\n",
    "monthly_stats = ndvi_from_zarr.NDVI.groupby('time.month').agg(['mean', 'std', 'min', 'max'])\n",
    "\n",
    "# Compute\n",
    "seasonal_computed = seasonal_mean.compute()\n",
    "monthly_stats_computed = monthly_stats.compute()\n",
    "\n",
    "# Visualize seasonal patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot each season\n",
    "seasons = ['DJF', 'MAM', 'JJA', 'SON']\n",
    "for idx, season in enumerate(seasons):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    if season in seasonal_computed.season:\n",
    "        seasonal_computed.sel(season=season).plot(\n",
    "            ax=ax, cmap='RdYlGn', vmin=-1, vmax=1\n",
    "        )\n",
    "        ax.set_title(f'{season} Mean NDVI')\n",
    "        ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, 'seasonal_ndvi.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db88af9",
   "metadata": {},
   "source": [
    "### Step 5: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71abe29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed results to Zarr\n",
    "results_path = os.path.join(output_folder, 'ndvi_analysis_results.zarr')\n",
    "\n",
    "print(f\"\\nSaving analysis results to: {results_path}\")\n",
    "\n",
    "results_computed.to_zarr(\n",
    "    results_path,\n",
    "    mode='w',\n",
    "    consolidated=True\n",
    ")\n",
    "\n",
    "# Also save as NetCDF for compatibility\n",
    "netcdf_path = os.path.join(output_folder, 'ndvi_timeseries.nc')\n",
    "ndvi_from_zarr.to_netcdf(netcdf_path)\n",
    "\n",
    "print(f\"\u2713 Saved to NetCDF: {netcdf_path}\")\n",
    "\n",
    "# Close Dask client\n",
    "client.close()\n",
    "cluster.close()\n",
    "\n",
    "print(\"\\n\u2713 All processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26415431",
   "metadata": {},
   "source": [
    "## Complete Workflow Comparison\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Approach | Pros | Cons | Best For |\n",
    "| --- | --- | --- | --- |\n",
    "| **Geemap Download** | Full local control, offline analysis | Requires storage, download time | Repeated analysis, offline work |\n",
    "| **XEE Streaming** | No storage needed, always latest data | Requires internet, slower for repeated queries | Exploratory analysis, prototyping |\n",
    "| **Dask + Zarr** | Scalable, efficient, cloud-ready | Initial setup complexity | Large-scale analysis, production |\n",
    "\n",
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af107f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Benchmark each approach\n",
    "print(\"\\n=== Performance Comparison ===\\n\")\n",
    "\n",
    "# 1. Geemap + XArray\n",
    "start = time.time()\n",
    "result1 = ndvi_ts.mean(dim='time').values\n",
    "time1 = time.time() - start\n",
    "print(f\"Geemap + XArray: {time1:.2f} seconds\")\n",
    "\n",
    "# 2. XEE (if loaded)\n",
    "start = time.time()\n",
    "result2 = ndvi_monthly_xee.mean(dim='time').compute().values\n",
    "time2 = time.time() - start\n",
    "print(f\"XEE Streaming: {time2:.2f} seconds\")\n",
    "\n",
    "# 3. Dask + Zarr\n",
    "start = time.time()\n",
    "result3 = ndvi_from_zarr.NDVI.mean(dim='time').compute().values\n",
    "time3 = time.time() - start\n",
    "print(f\"Dask + Zarr: {time3:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nFastest approach: \", end=\"\")\n",
    "times = {'Geemap': time1, 'XEE': time2, 'Zarr': time3}\n",
    "print(min(times, key=times.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abb080c",
   "metadata": {},
   "source": [
    "## Complete Example Script\n",
    "\n",
    "Here's the full script combining all approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96fd2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Complete Time Series Analysis Workflow\n",
    "Demonstrates: Geemap Download \u2192 XArray \u2192 XEE \u2192 Dask \u2192 Zarr\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "import xarray as xr\n",
    "import xee\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from pathlib import Path\n",
    "import os\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "ROI = ee.Geometry.Rectangle([82.0, 26.5, 82.5, 27.0])\n",
    "YEAR = 2023\n",
    "OUTPUT_FOLDER = 'timeseries_analysis'\n",
    "SCALE = 20  # meters\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run complete workflow.\"\"\"\n",
    "    \n",
    "    # Initialize\n",
    "    ee.Initialize(project='spatialgeography')\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CLOUD-NATIVE TIME SERIES ANALYSIS WORKFLOW\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Approach 1: Geemap Download\n",
    "    print(\"\\n[1/3] Geemap Tiled Download...\")\n",
    "    monthly_files = download_monthly_ndvi(ROI, YEAR, OUTPUT_FOLDER)\n",
    "    ndvi_xarray = load_with_xarray(monthly_files)\n",
    "    analyze_timeseries(ndvi_xarray, OUTPUT_FOLDER)\n",
    "    \n",
    "    # Approach 2: XEE Streaming\n",
    "    print(\"\\n[2/3] XEE Streaming...\")\n",
    "    ndvi_xee = stream_with_xee(ROI, YEAR)\n",
    "    compare_approaches(ndvi_xarray, ndvi_xee, OUTPUT_FOLDER)\n",
    "    \n",
    "    # Approach 3: Dask + Zarr\n",
    "    print(\"\\n[3/3] Dask + Zarr Processing...\")\n",
    "    process_with_dask_zarr(monthly_files, OUTPUT_FOLDER)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\u2713 WORKFLOW COMPLETE!\")\n",
    "    print(f\"Results saved to: {OUTPUT_FOLDER}/\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "def download_monthly_ndvi(roi, year, output_folder):\n",
    "    \"\"\"Download monthly NDVI using geemap.\"\"\"\n",
    "    # Implementation from Approach 1\n",
    "    pass\n",
    "\n",
    "def load_with_xarray(files):\n",
    "    \"\"\"Load files with XArray.\"\"\"\n",
    "    # Implementation from Approach 1\n",
    "    pass\n",
    "\n",
    "def analyze_timeseries(data, output_folder):\n",
    "    \"\"\"Analyze time series.\"\"\"\n",
    "    # Implementation from Approach 1\n",
    "    pass\n",
    "\n",
    "def stream_with_xee(roi, year):\n",
    "    \"\"\"Stream data with XEE.\"\"\"\n",
    "    # Implementation from Approach 2\n",
    "    pass\n",
    "\n",
    "def compare_approaches(data1, data2, output_folder):\n",
    "    \"\"\"Compare different approaches.\"\"\"\n",
    "    # Implementation from comparison section\n",
    "    pass\n",
    "\n",
    "def process_with_dask_zarr(files, output_folder):\n",
    "    \"\"\"Process with Dask and save to Zarr.\"\"\"\n",
    "    # Implementation from Approach 3\n",
    "    pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc049e0e",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "!!! success \"What You Learned\"\n",
    "    - **Geemap**: Download large time series without EECU, automatic tiling\n",
    "    - **XArray**: Powerful time series analysis with labeled dimensions\n",
    "    - **XEE**: Stream Earth Engine data directly without downloads\n",
    "    - **Dask**: Parallel processing for large datasets\n",
    "    - **Zarr**: Cloud-optimized storage with compression\n",
    "    - **Integration**: Combine tools for optimal workflow\n",
    "    - **Performance**: Choose the right tool for your use case\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Next: [Time Series and Phenological Methods](timeseries-phenology.ipynb)\n",
    "- Learn [Optimization Techniques](../advanced/optimization.ipynb) for better performance\n",
    "- Back: [Classification Methods](classification-methods.ipynb)\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [geemap Examples](https://geemap.org/notebooks/)\n",
    "- [XArray Time Series](https://docs.xarray.dev/en/stable/user-guide/time-series.html)\n",
    "- [Dask Best Practices](https://docs.dask.org/en/stable/best-practices.html)\n",
    "- [Zarr Tutorial](https://zarr.readthedocs.io/en/stable/tutorial.html)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}